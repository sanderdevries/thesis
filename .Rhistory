beetle.IWRLS <- NewtonRaphson(bstar)
beetle <- NewtonRaphson(bstar)
GLM <- glm(cbind(y,n-y)~x,family=binomial)
summary(beetle.glm)
summary(GLM)
IWRLS
IWRLS <- NewtonRaphson(beta)
IWRLS
x <- c(1.6907,1.7242,1.7552,1.7842,1.8113,1.8369,1.8610,1.8839)
n <- c(59,60,62,56,63,59,62,60)
y <- c(6,13,18,28,52,53,61,60)
beta <- c(0.5,0.5)
S <- c(1,1)
NewtonRaphson <- function(beta,eps=1e-5,maxiter=10^4){
b <- bstar
iter <- 0
pi <- (exp(b[1]+b[2]*x))/(1+exp(b[1]+b[2]*x))
S <- c(sum(y-n*pi),sum(y*x-n*x*pi))
J <- matrix(1,2,2)
J[1,1] <- sum(n*pi*(1-pi))
J[1,2] <- sum(n*x*pi*(1-pi))
J[2,1] <- J[1,2]
J[2,2] <- sum(n*x*x*pi*(1-pi))
absolute <- abs(S[1]) + abs(S[2])
while(absolute > eps && iter < maxiter){
inverse <- solve(J)
b <- b + solve(J) %*% S
pi <- (exp(b[1]+b[2]*x))/(1+exp(b[1]+b[2]*x))
S <- c(sum(y-n*pi),sum(y*x-n*x*pi))
J[1,1] <- sum(n*pi*(1-pi))
J[1,2] <- sum(n*x*pi*(1-pi))
J[2,1] <- J[1,2]
J[2,2] <- sum(n*x*x*pi*(1-pi))
iter <- iter + 1
absolute <- abs(S[1]) + abs(S[2])
}
if (absolute > eps){
cat("Failed to converge\n")
return(NULL)
} else{
cat("Converged at", iter, "iterations with the coefficients: beta1 = ", b[1], "and beta2 = ", b[2])
return(b)
}
}
IWRLS <- NewtonRaphson(beta)
IWRLS
summary(GLM)
summary(GLM)
library(LARF)
install.packages("LARF")
library(LARF)
data(c401k)
summary(c401k)
View(c401k)
plot(c401k$pira)
density(c401k$pira)
plot(density(c401k$pira))
table(c401k$pira)
summary(c401k)
table(c401k$pira, c401k$p401k)
table(c(c401k$pira, c401k$p401k))
rbind(table(c401k$pira), table(c401k$p401k))
rbind("pira" = table(c401k$pira),"p401k" = table(c401k$p401k))
rbind("pira" = table(c401k$pira),"p401k" = table(c401k$p401k),"e401k" = table(c401k$e401k), "marr" = table(c401k$marr), "male" = table(c401k$male))
table("fsize" = table(c401k$fsize))
summary(c401k)
rbind("pira" = table(c401k$pira),"p401k" = table(c401k$p401k),"e401k" = table(c401k$e401k), "marr" = table(c401k$marr), "male" = table(c401k$male))
cdplot(pira ~ nettfa, data=c401k)
cdplot(c401k$pira ~ c401k$nettfa)
cdplot(pira ~ nettfa, data=c401k)
pira
c401k$pira
c401k$pira <- as.factor(c401k$pira)
cdplot(pira ~ nettfa, data=c401k)
cdplot(pira ~ nettfa, data=c401k)
cdplot(pira ~ inc, data=c401k)
cdplot(pira ~ p401k, data=c401k)
cdplot(pira ~ age, data=c401k)
cdplot(pira ~ fsize, data=c401k)
cdplot(pira ~ inc, data=c401k)
cdplot(pira ~ age, data=c401k)
cdplot(pira ~ fsize, data=c401k)
summary(fullModel)
fullModel <- glm(pira ~1+nettfa+p401k+e401k+inc+marr+male+age+fsize,data=c401k)
summary(fullModel)
data("c401k")
fullModel <- glm(pira ~1+nettfa+p401k+e401k+inc+marr+male+age+fsize,data=c401k)
summary(fullModel)
cdplot(pira ~ age, data=c401k)
c401k$pira <- as.factor(c401k$pira)
cdplot(pira ~ age, data=c401k)
data("c401k")
fullModel <- glm(pira ~1+nettfa+p401k+e401k+inc+marr+male+age+fsize,data=c401k)
summary(fullModel)
c401k$pira <- as.factor(c401k$pira)
cdplot(pira ~ inc, data=c401k)
cdplot(pira ~ age, data=c401k)
combinations2 <- expand.grid(c(TRUE,TRUE), c(TRUE,TRUE),c(TRUE,TRUE), c(TRUE,TRUE),c(TRUE,FALSE),c(TRUE,TRUE),c(TRUE, TRUE),c(TRUE,FALSE),c(TRUE,TRUE),c(TRUE,TRUE))
list2 <- apply(combinations2, 1, function(x) as.formula(paste(c("pira ~ 1", combinations2[x]),collapse="+")) )
list2 <- apply(combinations2, 1, function(x) as.formula(paste(c("pira ~ 1", combinations2[x]),collapse="+")) )
models <- lapply(allModelsList2, function(x) glm(x, data=c401k))
models <- lapply(list2, function(x) glm(x, data=c401k))
combinations2 <- expand.grid(c(TRUE,TRUE), c(TRUE,TRUE),c(TRUE,TRUE), c(TRUE,TRUE),c(TRUE,FALSE),c(TRUE,TRUE),c(TRUE, TRUE),c(TRUE,FALSE),c(TRUE,TRUE),c(TRUE,TRUE))
combinations2
combinations2 <- expand.grid(TRUE, c(TRUE,TRUE),c(TRUE,TRUE), c(TRUE,TRUE),c(TRUE,FALSE),c(TRUE,TRUE),c(TRUE, TRUE),c(TRUE,FALSE),c(TRUE,TRUE),c(TRUE,TRUE))
combinations2
combinations2 <- expand.grid(TRUE, TRUE,TRUE, TRUE,c(TRUE,FALSE),TRUE,TRUE, c(TRUE,FALSE),TRUE,TRUE)
combinations2
list2 <- apply(combinations2, 1, function(x) as.formula(paste(c("pira ~ 1", combinations2[x]),collapse="+")) )
models <- lapply(list2, function(x) glm(x, data=c401k))
list2
combinations2
list2 <- apply(combinations2, 1,
function(x) as.formula(paste(c("pira ~ 1", combinations2[x]),collapse="+"))
)
list2
combinations2
predictors2 <- c("nettfa", "p401k","e401k","inc", "incsq","marr","male","age","agesq","fsize")
combinations2 <- expand.grid(TRUE, TRUE,TRUE, TRUE,c(TRUE,FALSE),TRUE,TRUE, c(TRUE,FALSE),TRUE,TRUE)
list2 <- apply(combinations2, 1,
function(x) as.formula(paste(c("pira ~ 1", predictors2[x]),collapse="+"))
)
models <- lapply(list2, function(x) glm(x, data=c401k))
list2
models <- lapply(list2, function(x) glm(x, data=c401k))
predictors2 <- c("nettfa", "p401k","e401k","inc", "incsq","marr","male","age","agesq","fsize")
combinations2 <- expand.grid(TRUE, TRUE,TRUE, TRUE,c(TRUE,FALSE),TRUE,TRUE, c(TRUE,FALSE),TRUE,TRUE)
list2 <- apply(combinations2, 1,
function(x) as.formula(paste(c("pira ~ 1", predictors2[x]),collapse="+"))
)
list2
combinations2 <- expand.grid(TRUE, TRUE,TRUE, TRUE,c(TRUE,FALSE),TRUE,TRUE, TRUE,c(TRUE, FALSE),TRUE)
list2 <- apply(combinations2, 1,
function(x) as.formula(paste(c("pira ~ 1", predictors2[x]),collapse="+"))
)
list2
models2 <- lapply(list2, function(x) glm(x, data=c401k))
predictors2
list2
data("c401k")
predictors2 <- c("nettfa", "p401k","e401k","inc", "incsq","marr","male","age","agesq","fsize")
combinations2 <- expand.grid(TRUE, TRUE,TRUE, TRUE,c(TRUE,FALSE),TRUE,TRUE, TRUE,c(TRUE, FALSE),TRUE)
list2 <- apply(combinations2, 1,
function(x) as.formula(paste(c("pira ~ 1", predictors2[x]),collapse="+"))
)
models2 <- lapply(list2, function(x) glm(x, data=c401k))
models2
models2
AICvalues2 <- sapply(models2, FUN=AIC)
sapply(models2, FUN=AIC)
lapply(list2[3], function(x) lm(x, data=c401k))
summary(lapply(list2[3], function(x) lm(x, data=c401k)))
lapply(list2[3], function(x) lm(x, data=c401k))
summary(lm(pira ~ 1 + nettfa + p401k + e401k + inc + incsq + marr + age + fsize, data = c401k))
summary(lm(pira ~ 1 + nettfa + p401k + e401k + inc + incsq + marr + age + fsize, data = c401k))
x <- c(18,31,34,33,27,33,28,23,33,12,19,25,14,4,22,7)
fem <- c(18,31,34,33,27,33,28,23,33,12,19,25,14,4,22,7)
mal <- c(11,22,27,29,24,29,25,26,38,14,23,31,20,6,34,12)
fem
fem <- t(c(18,31,34,33,27,33,28,23,33,12,19,25,14,4,22,7))
mal <- t(c(11,22,27,29,24,29,25,26,38,14,23,31,20,6,34,12))
fem
data <- cbind(fem, mal)
data
data <- rbind(fem, mal)
data
data <- t(rbind(fem, mal))
data
data <- data.frame(t(rbind(fem, mal)))
data
colnames(data) = c( "female" , "male")
data
data$prop <- data$female/(data$female + data$male)
data
MLE <- sum(data$prop)/length(data$prop)
MLE
data$female[,1] + data$male[,2]
data
data$total <- data$male + data$female
data
n <- data[,4]
y <- data[,1]
n
y
pdf <- factorial(n)/(factorial(y)*factorial(n-y))*p^y*(1-p)^(n-y)
p <- 0.5
pdf <- factorial(n)/(factorial(y)*factorial(n-y))*p^y*(1-p)^(n-y)
pdf
loglik <- function(p){
n <- data[,4]
y <- data[,1]
pdf <- factorial(n)/(factorial(y)*factorial(n-y))*p^y*(1-p)^(n-y)
sum(log(pdf))
}
MLE.E <- optim(p, loglik, control = fnscale(list = -1))
?optim
MLE.E <- optim(p, loglik, control = list(fnscale = -1))
MLE.E
MLE
rm(list = ls())
y <- Leukemia <- c(13, 5, 5, 3, 4, 18)
n <- total <- c(391, 205, 156, 50, 35, 51)     # (a) : binomial model with logit link
x <- Radiation.dose <- c(0, 1, 10, 50, 100, 200)
res.glm1 <- glm(cbind(y, n - y) ~ x, family = binomial(link = "logit"))
summary(res.glm1)                              # (b) Residual deviance: 0.43206 small wrt df=4 indicates good fit
library(binomTools)
(Rsq.glm1 <- Rsq(res.glm1))                    # pseudo R^2 indicated rather small fit of the model to the data
plot(Rsq.glm1, "ecdf")
xx <- seq(0,200,0.1)        # construct sequence of numbers horizontal axis
summary(res.glm1)                              # (b) Residual deviance: 0.43206 small wrt df=4 indicates good fit
xx <- seq(0,200,0.1)        # construct sequence of numbers horizontal axis
pi <- exp(res.glm1$coef[1]+res.glm1$coef[2]*xx)/(1+exp(res.glm1$coef[1]+res.glm1$coef[2]*xx))
plot(xx,pi,type="l",xlab="Radiation",ylab="Proportion with leukemia")
pd <- y/n
points(x,pd)      #added curve fits data points precisely
summary(res.glm1)                              # (b) Residual deviance: 0.43206 small wrt df=4 indicates good fit
pi <- exp(res.glm1$coef[1]+res.glm1$coef[2]*xx)/(1+exp(res.glm1$coef[1]+res.glm1$coef[2]*xx))
plot(xx,pi,type="l",xlab="Radiation",ylab="Proportion with leukemia")
pd <- y/n
points(x,pd)      #added curve fits data points precisely
cbind(exp(summary(res.glm1)$coef)[,1], exp(confint(res.glm1)))
# some additional code improving insight
beta1 <- summary(res.glm1)$coef[1,1]
beta2 <- summary(res.glm1)$coef[2,1]
(pihat <- 1 / (1 + exp( - (beta1 + beta2 * x)))) #= fitted.values(res.glm1)
(yhat <- n * pihat)
data.frame(y,yhat)
(X2 <-  sum(((y - n * pihat)^2) / (n * pihat * (1 - pihat)))) # asymptotic chi-square distr with df=N-p; p.136
N <- 6; p <- 2
(p.value <- pchisq(X2, df=N-p, ncp=0, lower.tail = FALSE))
df <- N - p
shape <- df / 2; scale <- 1 / 2
(pvalue <- pgamma(X2, shape, scale, lower.tail = FALSE))
(pihat <- 1 / (1 + exp( - (beta1 + beta2 * x)))) #= fitted.values(res.glm1)
(yhat <- n * pihat)
data.frame(y,yhat)
(X2 <-  sum(((y - n * pihat)^2) / (n * pihat * (1 - pihat)))) # asymptotic chi-square distr with df=N-p; p.136
N <- 6; p <- 2
(p.value <- pchisq(X2, df=N-p, ncp=0, lower.tail = FALSE))
library(readr)
dataset <- read_delim("Documents/OneDrive/Documenten/E&OR/GLM/data 3/Table 8.5HousingConditions.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(dataset)
housing <- dataset
housing$contact <- gl(2,1,18,labels=c("low","high"),ordered=TRUE)
with(housing, xtabs(frequency ~ type + contact + satisfaction)) #Table 8.5
nom.model0 <- multinom(satisfaction ~ type * contact, weights=frequency, data=housing) #maximal model
library(MASS)
library(MASS)
nom.model0 <- multinom(satisfaction ~ type * contact, weights=frequency, data=housing) #maximal model
library(nnet)
nom.model0 <- multinom(satisfaction ~ type * contact, weights=frequency, data=housing) #maximal model
nom.model1 <- multinom(satisfaction ~ type + contact, weights=frequency, data=housing) #all variables
nom.model2 <- multinom(satisfaction ~  contact, weights=frequency, data=housing) #only contact
nom.model3 <- multinom(satisfaction ~  type, weights=frequency, data=housing) #only  type
anova(nom.model1,nom.model0)
anova(nom.model2,nom.model1)
anova(nom.model3,nom.model1)
summary(nom.model1)  #(b)
ord.model1 <- polr(ordered(satisfaction) ~ type + contact, weights=frequency, data=housing) # proportional odds logistic regression
ord.model2 <- polr(ordered(satisfaction) ~ contact, weights=frequency, data=housing)
ord.model3 <- polr(ordered(satisfaction) ~ type, weights=frequency, data=housing)
anova(ord.model2,ord.model1)
anova(nom.model3,nom.model1) #reject H0:contact is zero
anova(nom.model2,nom.model1) #reject H0: type is zero
anova(ord.model2,ord.model1) #reject H0: type is zero
anova(ord.model3,ord.model1)  # model with only type is best
a <-  housing$frequency * fitted(ord.model3)
e <- vector()
fitted(ord.model3)
e <- vector()
housing$satisfaction[10]
for (i in 1:18) {e[i] <-  a[i,housing$satisfaction[i]]}  #select expected frequencies per satisfaction level each observation
o <- housing$frequency
data.frame(o,e,(o-e),(o-e)/sqrt(e))  # (d) some residuals are quite large
library(readr)
Table_8_6TumorResponse <- read_delim("Documents/OneDrive/Documenten/E&OR/GLM/data 3/Table 8.6TumorResponse.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(Table_8_6TumorResponse)
tumor <- Table_8_6TumorResponse
ord.model1 <- polr(ordered(response) ~ treatmen + sex, weights=frequency, data=tumor) # proportional odds logistic regression
ord.model1 <- polr(ordered(response) ~ treatment + sex, weights=frequency, data=tumor) # proportional odds logistic regression
fitted(ord.model1)
e <- rep(NA, 16)
a <-  tumor$frequency * fitted(ord.model1)
a
e <- vector()
for (i in 1:16) {e[i] <-  a[i,tumor$response[i]]}  #select expected frequencies per satisfaction level each observation
o <- tumor$frequency
data.frame(o,e,(o-e),(o-e)/sqrt(e))  # (d) some residuals are quite large
X <- sum((o-e)^2/sqrt(e))
X
pchisq(X, 16)
pchisq(X, 10)
X <- sum((o-e)^2/sqrt(e)) #follows an (16-6) degrees of freedom Chi square
(o-e)^2/sqrt(e)
tumor <- Table_8_6TumorResponse
ord.model1 <- polr(ordered(response) ~ treatment + sex, weights=frequency, data=tumor) # proportional odds logistic regression
a <-  tumor$frequency * fitted(ord.model1)
e <- vector()
for (i in 1:16) {e[i] <-  a[i,tumor$response[i]]}  #select expected frequencies per satisfaction level each observation
o <- tumor$frequency
o
e
tumor <- Table_8_6TumorResponse
ord.model1 <- polr(ordered(response) ~ treatment + sex, weights=frequency, data=tumor) # proportional odds logistic regression
model1 <- polr(ordered(response) ~ treatment + sex, weights=frequency, data = tumor)
summary(mod1)
mod1 <- polr(ordered(response) ~ treatment + sex, weights=frequency, data = tumor)
summary(mod1)
#8.3 (c)
summary(mod1)   # Wald t-value  -2.128 borderline significantly different from 0
install.packages("faraway")
library(faraway)
install.packages("nlme")
install.packages("nlme")
install.packages("nlme")
library(installr)
install.packages(installr)
install.packages("installr")
install.packages('installr',repos='http://cran.us.r-project.org')
load(installr)
load("installr")
install.packages('devtools') #assuming it is not already installed
library(devtools)
install_github('andreacirilloac/updateR')
install.packages('devtools') #assuming it is not already installed
library(devtools)
install_github('andreacirilloac/updateR')
library(updateR)
install.packages("devtools")
install.packages('devtools') #assuming it is not already installed
library(devtools)
install_github('andreacirilloac/updateR')
library(updateR)
updateR()
install.packages("installr")
library(installr)
library(installr)
updateR()
install.packages("stringi")
install.packages("stringi")
setwd("~/Code/R/Thesis")
m.files <- list.files(path = "lifetables", full.names = FALSE)
#install.packages("HMDHFDplus")
library(HMDHFDplus)
forceType <- function(z){
z <- z[-1,]
colnames(z) <- as.character(unlist(z[1,]))
z = z[-1, 1:10]
z$Age <- age2int(z$Age)
z$Year <- as.integer(as.character(z$Year))
for(i in 3: 10){
z[,i] <- as.numeric(as.character(z[,i]))
}
z
}
fdata <- forceType(read.delim(m.files[1], header = FALSE, sep = "", dec = "."))
mdata <- forceType(read.delim(m.files[2], header = FALSE, sep = "", dec = "."))
#merge male and female to obtain unisex data
library(plyr)
udata <- join(fdata, mdata, by = c("Year", "Age"))
udata[,6] <- udata[,6] + udata[,14]
udata <- udata[,c(1:2, 6)]
#this function creates a cohort for a given dataset 'z', with people bornin 'year',
#of initial age 'yearMin' and maximum age 'yearMax'
cohort <- function(z, year, yearMin, yearMax){
z <- z[ which(z$Year - z$Age == year), ]
z <- z[ which(z$Age > yearMin & z$Age < yearMax), ]
z
}
fcohort <- cohort(fdata,1915, 65, 110)
mcohort <- cohort(mdata,1915, 65, 110)
ucohort <- cohort(udata,1915, 65, 110)
#below the necessary functions are defined to compute the survival functions for both simple OU and jump OU processes
alpha.OU <- function(p,t){
mu <- p[1]
sigma <- abs(p[2])
(sigma^2/(2*mu^2))*t - (sigma^2/mu^3)*exp(mu*t) + (sigma^2/(4*mu^3))*exp(2*mu*t) + (3*sigma^2)/(4*mu^3)
}
alpha.OU.jump <- function(p,t){
mu <- p[1]
sigma <- p[2]
eta <- abs(p[3])
nu <- abs(p[4])
(sigma^2/(2*mu^2))*t - (sigma^2/mu^3)*exp(mu*t) + (sigma^2/(4*mu^3))*exp(2*mu*t) + (3*sigma^2)/(4*mu^3) + ((eta*nu)/(mu - nu))*t - (eta/(mu - nu)) * log(1 - (nu/mu) + (nu/mu)*exp(mu*t))
}
beta <- function(p, t){
a <- p[1]
(1/a) * (1-exp(a*t))
}
survival.OU <- function(p,t,z){
lambda <- -log(1- z$qx[1])
exp(alpha.OU(p,t) + beta(p, t)*lambda)
}
survival.OU.jump <- function(p,t,z){
lambda <- -log(1- z$qx[1])
exp(alpha.OU.jump(p,t) + beta(p, t)*lambda)
}
#computes the mean square error of the survival function
MSE.OU <- function(p, z){
difference <- rep(NA, nrow(z) - 1)
tpx <- rep(NA, nrow(z) - 1)
for(i in 1: nrow(z) - 1){
tpx[i] <- z$lx[i+1]/z$lx[1]
diff <- (tpx[i] - survival.OU(p,i,z))^2
difference[i] <- diff
}
sum(difference)/length(difference)
}
MSE.OU.jump <- function(p,z){
difference <- rep(NA, nrow(z) - 1)
tpx <- rep(NA, nrow(z) - 1)
for(i in 1: nrow(z) - 1){
tpx[i] <- z$lx[i+1]/z$lx[1]
diff <- (tpx[i] -survival.OU.jump(p,i, z))^2
difference[i] <- diff
}
sum(difference)/length(difference)
}
#calibration of the parameters using the optim function and minimizing the MSE w.r.t the parameters to be estimated
calibration.OU <- function(p.OU, z){
p.OU <- c(0.01, 0.001)
m.MSE.OU <- optim(p.OU, MSE.OU, z = z, hessian = TRUE)
par.OU <- c(m.MSE.OU$par[1], abs(m.MSE.OU$par[2]))
return(par.OU)
}
calibration.OU.j <- function(p.OU.j, z){
p.OU.j <- c(0.01, 0.0001, 0.01, 0.003)
m.MSE.OU.jump <- optim(p=p.OU.j, MSE.OU.jump,z= z)
par.OU.jump <- c( m.MSE.OU.jump$par[1], abs(m.MSE.OU.jump$par[2]), abs(m.MSE.OU.jump$par[3]), abs(m.MSE.OU.jump$par[4]))
return(par.OU.jump)
}
#observed survival probabilities
tpx <- function(z){
tpx <- rep(NA, nrow(z) - 1)
for(i in 1: nrow(z) - 1){
tpx[i] <- z$lx[i+1]/z$lx[1]
}
return(tpx)
}
#computes estimated survival probabilities given the calibrated parameters
estimated.density.OU <- function(z, t){
survival.OU(calibration.OU(p.OU,z), t, z)
}
estimated.density.OU.jump <- function(z, t){
survival.OU.jump(calibration.OU.j(z = z), t, z)
}
#Graphs the observed and estimated survival probabilities for any cohort 'z'
library(ggplot2)
graphs <- function(z){
obser <- data.frame(cbind(tpx(z), 1:(nrow(z) - 1)))
x.grid <- seq(0,to=nrow(z) - 1,by=0.01)
dd <- data.frame(x.grid,x2 = estimated.density.OU(z, t = x.grid), x3 = estimated.density.OU.jump(z, t = x.grid))
ggplot(z) +
geom_line(data=dd,aes(x=x.grid,y=x2, colour = "OU")) +
geom_line(data=dd,aes(x=x.grid,y=x3, colour = "OU Jump")) +
geom_line(data=obser, aes(x = X2, y = X1, colour = "Observed")) +
ylab("Survival probability") + xlab("Remaining lifetime") +
scale_colour_manual(values=c("red","blue", "green"))
}
#probability of intensity becoming negative
prob <- function(z, t){
mu <- calibration.OU.j(z = z)[1]
sigma <- calibration.OU.j(z = z)[2]
pnorm(log(1-z$qx[1])*exp(mu*t)/(sigma * sqrt((exp(2* mu*t )-1)/(2*mu))))
}
#make a table of estimates of the OU process for 3 cohorts
mestimates <- matrix(ncol = 3, nrow = 4)
colnames(mestimates) <- c("1885", "1900", "1915")
rownames(mestimates) <- c("mu", "sigma", "MSE", "lambda_0")
festimates <- matrix(ncol = 3, nrow = 4)
colnames(festimates) <- c("1885", "1900", "1915")
rownames(festimates) <- c("mu", "sigma", "MSE", "lambda_0")
year <- c(1885, 1900, 1915)
for(i in 1:3){
mestimates[,i ] <- c(calibration.OU(z = cohort(mdata,year[i], 65, 110)),
MSE.OU(calibration.OU(z = cohort(mdata,year[i], 65, 110)), z = cohort(mdata,year[i], 65, 110)),
-log(1-cohort(mdata, year[i], 65, 110)$qx[1]))
festimates[,i ] <- c(calibration.OU(z = cohort(fdata,year[i], 65, 110)),
MSE.OU(calibration.OU(z = cohort(fdata,year[i], 65, 110)), z = cohort(fdata,year[i], 65, 110)),
-log(1-cohort(fdata, year[i], 65, 110)$qx[1]))
}
#now for the OU process with jump
mestimates.j <- matrix(ncol = 3, nrow = 6)
colnames(mestimates.j) <- c("1885", "1900", "1915")
rownames(mestimates.j) <- c("mu", "sigma", "eta", "nu", "MSE", "lambda_0")
festimates.j <- matrix(ncol = 3, nrow = 6)
colnames(festimates.j) <- c("1885", "1900", "1915")
rownames(festimates.j) <- c("mu", "sigma", "eta", "nu", "MSE", "lambda_0")
year <- c(1885, 1900, 1915)
for(i in 1:3){
mestimates.j[,i ] <- c(calibration.OU.j(z = cohort(mdata,year[i], 65, 110)),
MSE.OU.jump(calibration.OU.j(z = cohort(mdata,year[i], 65, 110)), z = cohort(mdata,year[i], 65, 110)),
-log(1-cohort(mdata, year[i], 65, 110)$qx[1]))
festimates.j[,i ] <- c(calibration.OU.j(z = cohort(fdata,year[i], 65, 110)),
MSE.OU.jump(calibration.OU.j(z = cohort(fdata,year[i], 65, 110)), z = cohort(fdata,year[i], 65, 110)),
-log(1-cohort(fdata, year[i], 65, 110)$qx[1]))
}
#defines the shocked survival probability density
shockSurvival <- function(t, e, z){
estimated.density.OU.jump(z=z, t =t)^(1+e)
}
#computes the estimated shocked mortality as a function of the shock e and using the graph,
#we can visualize the severity of the shock in order for the shocked mortality to be 15 percent higher after 1 year
par.OU.j = calibration.OU.j(z = fcohort)
x <- seq(0, to = 0.2, by = 0.001)
est.mortality <- 1 - shockSurvival(x, t = 1, z = fcohort)
SS <- data.frame(x, est.mortality, qs = (1+0.15)*(1-survival.OU.jump(par.OU.j, t = 1, z = fcohort)))
ggplot(SS) +
geom_line(data = SS, aes(x = x, y = est.mortality))+
geom_line(data = SS, aes(x = x, y = qs )) #the intercept is somewhere around e = 0.15 for female data
